## NFS网络文件系统

NFS，网络文件系统，为客户端提供透明的文件访问。NFS的基础是Sun RPC(Romote Procedure Call)，远程过程调用。NFS是运行在应用层的协议。

### RPC
大多数的网络程序设计都是客户发送命令给服务器，服务器向客户发送应答，比如Ping、Traceroute、DNS、SNMP、Telenet、Ftp和SMTP的客户和服务器。RPC是一种不同的网络程序设计方法。客户端程序只是调用了服务器程序提供的函数。

![](https://gitarticle.oss-cn-shanghai.aliyuncs.com/network/images/rpc.webp)

一个完整的RPC架构里面包含了四个核心的组件，分别是`Client` ,`Server`,`Client Stub`以及`Server Stub`，这个Stub大家可以理解为`存根`。

1. 当客户程序调用远程的过程时，它实际上只是调用了一个位于本机上的、由 RPC程序包生成的函数。这个函数被称为`Client Stub`。`Client Stub`将过程的参数封装成一个网络报文，并且将这个报文发送给服务器程序。
2. 服务器主机上的一个`Server Stub`负责接收这个网络报文。它从网络报文中提取参数，然后调用应用程序员编写的服务器过程。
3. 当服务器函数返回时，它返回到`Server Stub`。`Server Stub`提取返回值，把返回值封装成一个网络报文，然后将报文发送给`Client Stub`。
4. `Client Stub`从接收到的网络报文中取出返回值，将其返回给客户程序。

网络程序设计是通过`Stub`和使用诸如SOCKET或TLI的某个API的RPC库例程来实现的，但是
用户程序—客户程序和被客户程序调用的服务器过程—不会和这个API打交道。客户应用
程序只是调用服务器的过程，所有网络程序设计的细节都被RPC程序包、`Client Stub`和`Client Stub`所隐藏。

一个RPC程序包提供了很多好处。
1. 程序设计更加容易，因为很少或几乎没有涉及网络编程。应用程序设计员只需要编写一个客户程序和客户程序调用的服务器过程。
2. 如果使用了一个不可靠的协议，如UDP，像超时和重传等细节就由RPC程序包来处理。这就简化了用户应用程序。
3. RPC库为参数和返回值的传输提供任何需要的数据转换。例如，如果参数是由整数和浮点数组成的， RPC程序包处理整数和浮点数在客户机和服务器主机上存储的不同形式。这个功能简化了在异构环境中的客户和服务器的编码问题。

`Sun RPC` 有两个版本。一个版本建立在SOCKET API基础上，和TCP和UDP打交道。另一个称为TI-RPC的（独立于运输层），建立在TLI API基础上，可以和内核提供的任何运输层协议打交道。

![](https://gitarticle.oss-cn-shanghai.aliyuncs.com/network/images/rpc-call.png)
![](https://gitarticle.oss-cn-shanghai.aliyuncs.com/network/images/rpc-reply.png)

事务标识符`XID`由客户程序设置，由服务器程序返回。当客户收到一个应答，它将服务器返回的`XID`与它发送的请求的`XID`相比较。如果不匹配，客户就放弃这个报文，等待从服务器返回的下一个报文。每次客户发出一个新的RPC，它就会改变报文的`XID`。但是如果客户重传一个以前发送过的 RPC（因为它没有收到服务器的一个应答），重传报文的`XID`不会修改。

调用(call)变量在过程调用报文中设置为0，在应答报文中设置为1。

如果使用的不是UDP而是TCP，因为TCP是一个字节流协议，没有记录边界，所以没有固定的长度。为了解决这个问题，在TCP首部和XID之间增加了一个4字节的长度字段，告诉接收者这个RPC调用由多少节组成。这也使得一个RPC调用报文在必要时可以用多个TCP段来传输。

#### 端口映射器
包含远程过程的RPC服务器程序使用的是临时端口，而不是知名端口。

一个进程必须有超级用户权限才能给自己分配一个小于1024的端口号（一个知名端口）。尽管这对于系统提供的服务器没问题，如 Telnet服务器、FTP服务器、和端口映射器，但我们不想给所有的RPC服务器提供这个权限。

这就需要某种形式的注册程序来跟踪哪一个RPC程序使用了哪一个临时端口。在 Sun RPC中，这个注册程序被称为**端口映射器**`port mapper`。
**端口**这个词作为Internet协议族的一个特征，来自于TCP和UDP端口号。既然TI-RPC可以工作在任何运输层协议之上，而不仅仅是TCP和UDP，所以使用TI-RPC的系统中(如SVR4和Solaris 2.2)，端口映射器的名字变成了rpcbind。下面我们继续使用更为常见的端口映射器的名字。

很自然地，端口映射器本身必须有一个知名端口：UDP端口**111**和TCP端口**111**。端口映射器也就是一个RPC服务器程序。它有一个程序号(**100000**)、一个版本号(2)、一个TCP端口111和一个UDP端口111。服务器程序使用RPC调用向端口映射器注册自身，客户程序使用RPC调用向端口映射器查询。

端口映射器提供四个服务过程：
1. **PMAPPROC_SET**。一个RPC服务器启动时调用这个过程，注册一个程序号、版本号和带有一个端口号的协议。
2. **PMAPPROC_UNSET**。RPC服务器调用此过程来删除一个已经注册的映射。
3. **PMAPPROC_GETPORT**。一个RPC客户启动时调用此过程。根据一个给定的程序号、版本号和协议来获得注册的端口号。
4. **PMAPPROC_DUMP**。返回端口映射器数据库中所有的记录（每个记录包括程序号、版本号、协议和端口号）

在一个RPC服务器程序启动，接着被一个RPC客户程序调用的过程中，进行了以下一些步骤：
1. 一般情况下，当系统引导时，端口映射器必须首先启动。它创建一个TCP端点，并且被动打开TCP端口111。它也创建一个UDP端点，并且在UDP端口111等待着UDP数据报的到来。
2. 当RPC服务器程序启动时，它为它所支持的程序的每一个版本创建一个TCP端点和一个UDP端点（一个给定的RPC程序可以支持多个版本。客户调用一个服务器过程时，说明它想要哪一个版本）。两个端点各自绑定一个临时端口（TCP端口号和UDP端口号是否一致无关紧要）。服务器通过RPC调用端口映射器的**PMAPPROC_SET**过程，注册每一个程序、版本、协议和端口号。
3. 当RPC客户程序启动时，它调用端口映射器的**PMAPPROC_GETPORT**过程来获得一个指定程序、版本和协议的临时端口号。
4. 客户发送一个RPC调用报文给第3步返回的端口号。如果使用的是UDP，客户只是发送一个包含RPC调用报文（见图29-1）的UDP数据报到服务器相应的UDP端口。服务器发送一个包含RPC应答报文（见图29-2）的UDP数据报到客户作为响应。如果使用的是TCP，客户对服务器的TCP端口号做一个主动打开，然后在建立的TCP连接上发送一个RPC调用报文。服务器作为响应，在连接上发送一个RPC应答报文。

查看rpc信息命令`rpcinfo`。

### NFS

使用NFS，客户可以透明地访问服务器上的文件和文件系统。这不同于提供文件传输的FTP。FTP会产生文件一个完整的副本。 NFS只访问一个进程引用文件的那一部分，并且NFS的一个目的就是使得这种访问透明。这就意味着任何能够访问一个本地文件的客户程序不需要做任何修改，就应该能够访问一个 NFS文件。

NFS是运行在应用层的协议。所有权威资料都可以在RFC 1813中找到

NFS是一个使用Sun RPC构造的客户服务器应用程序。 NFS客户通过向一个NFS服务器发送RPC请求来访问其上的文件。尽管这一工作可以使用一般的用户进程来实现—即NFS客户可以是一个用户进程，对服务器进行显式调用，而服务器也可以是一个用户进程。

因为两个理由，NFS一般不这样实现。首先，访问一个NFS文件必须对客户透明。因此，NFS的客户调用是由客户操作系统代表用户进程来完成的。第二，出于效率的考虑，NFS服务器在服务器操作系统中实现。如果 NFS服务器是一个用户进程，每个客户请求和服务器应答（包括读和写的数据）将不得不在内核和用户进程之间进行切换，这个代价太大。

![](https://gitarticle.oss-cn-shanghai.aliyuncs.com/network/images/nfs-config.png)

图29-3显示了一个NFS客户和一个NFS服务器的典型配置，图中有很多地方需要注意：

1. 访问的是一个本地文件还是一个NFS文件对于客户来说是透明的。当文件被打开时，由内核决定这一点。文件被打开之后，内核将本地文件的所有引用传递给名为`本地文件访问`的框中，而将一个NFS文件的所有引用传递给名为`NFS客户`的框中。
2. NFS客户通过它的TCP/IP模块向NFS服务器发送RPC请求。NFS主要使用UDP，最新的实现也可以使用TCP。
3. NFS服务器在端口`2049`接收作为UDP数据报的客户请求。尽管NFS可以被实现成使用端口映射器，允许服务器使用一个临时端口，但是大多数的实现都是直接指定UDP端口`2049`。
4. 当NFS服务器收到一个客户请求时，它将这个请求传递给本地文件访问例程，后者访问服务器主机上的一个本地的磁盘文件。
5. NFS服务器需要花一定的时间来处理一个客户的请求。访问本地文件系统一般也需要一部分时间。在这段时间间隔内，服务器不应该阻止其他的客户请求得到服务。为了实现这一功能，大多数的NFS服务器都是**多线程的**—即服务器的内核中实际上有多个NFS服务器在运行。具体怎么实现依赖于不同的操作系统。既然大多数的Unix内核不是多线程的，一个共同的技术就是启动一个用户进程（常被称为`nfsd`）的多个实例。这个实例执行一个系统调用，使自己作为一个内核进程保留在操作系统的内核中。
6. 同样，在客户主机上，NFS客户需要花一定的时间来处理一个用户进程的请求。NFS客户向服务器主机发出一个RPC调用，然后等待服务器的应答。为了给使用NFS的客户主机上的用户进程提供更多的并发性，在客户内核中一般运行着多个NFS客户。同样，具体实现也依赖于操作系统。Unix系统经常使用类似于NFS服务器的技术：一个叫作`biod`的用户进程执行一个系统调用，作为一个内核进程保留在操作系统的内核中。

NFS实际上不仅仅由NFS协议组成。

应用程序|程序号|版本号|过程数
-----------|:----:|----:|--:
端口映射器  |100000|2    |4
NFS        |100003|2,3,4|15
安装程序    |100005|1    |5
加锁管理程序|100021|1,2,3|19
状态监视器  |100024|1    |6

在客户能够访问服务器上的文件系统之前，NFS客户主机必须调用安装守护程序。我们
在下面讨论安装守护程序。

加锁管理程序和状态监视器允许客户锁定一个NFS服务器上文件的部分区域。这两个程序独立于NFS协议，因为加锁需要知道客户和服务器的状态，而NFS本身在服务器上是无状态的。

### NFS 服务器主要进程
1. `rpc.nfsd`进程。 NFS服务的主进程，主要管理客户端是否能够接入NFS服务器以及数据的传输。该进程固定监听TCP/UDP 2049端口。

2. `rpc.mountd`。 进程管理和维护NFS文件系统，根据所设定的权限决定是否允许客户端挂载指定的共享目录。该进程监听的端口默认是不固定的。

3. `rpc.lockd` 进程（可选）。提供文件锁功能，防止多个客户端同时写入一个文件。该进程监听的端口默认是不固定的。

3. `rpc.statd` 进程（可选）。负责检查数据的状态及一致性，需要与 rpc.lockd 配合使用。该进程监听的端口默认是不固定的。

5. `rpcbind` 进程。RPC 的端口映射器进程，监听UDP 111端口。


### 文件句柄
NFS中一个基本概念是**文件句柄** (`file handle`)。它是一个不透明(opaque)的对象，用来引用
服务器上的一个文件或目录。不透明指的是服务器创建文件句柄，把它传递给客户，然后客户访问文件时，使用对应的文件句柄。客户不会查看文件句柄的内容—它的内容只对服务器有意义。

每次一个客户进程打开一个实际上位于一个NFS服务器上的文件时，NFS客户就会从NFS服务器那里获得该文件的一个文件句柄。每次NFS客户为用户进程读或写文件时，文件句柄就会传给服务器以指定被访问的文件。

一般情况下，用户进程不会和文件句柄打交道—只有NFS客户和NFS服务器将文件句柄传来传去。

Unix服务器一般在文件句柄中存储下面的信息：文件系统标识符（文件系统最大和最小的设备号），i-node号（在一个文件系统中唯一的数值）和一个i-node的生成码（每当一个i-node被一个不同的文件重用时就改变的数值）。

### 安装协议mount

客户必须在访问服务器上一个文件系统中的文件之前，使用安装协议安装那个文件系统。
一般情况下，这是在客户主机引导时完成的。最后的结果就是客户获得服务器文件系统的一
个文件句柄。

![](https://gitarticle.oss-cn-shanghai.aliyuncs.com/network/images/nfs-mount.png)

依次发生了下面的动作。
1. 服务器上的端口映射器一般在服务器主机引导时被启动。
2. 安装守护程序`mountd`在端口映射器之后被启动。它创建了一个TCP端点和一个UDP端点，并分别赋予一个临时的端口号。然后它在端口映射器中注册这些端口号。
3. 在客户机上执行`mount`命令，它向服务器上的端口映射器发出一个RPC调用来获得服务器上安装守护程序的端口号。客户和端口映射器交互既可以使用TCP也可以使用UDP，但一般使用UDP。
4. 端口映射器应答以安装守护程序的端口号。
5. `mount`命令向安装守护程序发出一个RPC调用来安装服务器上的一个文件系统。同样，既可以使用TCP也可以使用UDP，但一般使用UDP。服务器现在可以验证客户，使用客户的IP地址和端口号来判别是否允许客户安装指定的文件系统。
6. 安装守护程序应答以指定文件系统的`文件句柄`。
7. 客户机上的`mount命令`发出`mount系统调用`将第5步返回的文件句柄与客户机上的一个本地安装点联系起来。文件句柄被存储在NFS客户代码中，从现在开始，用户进程对于那个服务器文件系统的任何引用都将从使用这个文件句柄

上述实现技术将所有的安装处理，**除了**客户机上的`mount系统调用`，都放在用户进程中，而不是放在内核中。我们显示的三个程序—**mount命令**、**端口映射器**和**安装守护程序**—都是用户进程。

`sun # mount -t nfs bsdi:/usr /nfs/bsdi/usr`

这个命令将主机bsdi（一个NFS服务器）上的/usr目录安装成为本地文件系统/nfS/bsdi/usr

![](https://gitarticle.oss-cn-shanghai.aliyuncs.com/network/images/nfs-mount-wireshart.jpg)

### NFS过程
现在我们描述NFS服务器提供的15个过程（使用的个数与NFS过程的实际个数不一样，因为我们把它们按照功能分了组）。

1. **GETATTR**。返回一个文件的属性：文件类型（一般文件，目录等）、访问权限、文件大小、文件的属主者及上次访问时间等信息。
2. **SETATTR**。设置一个文件的属性。只允许设置文件属性的一个子集：访问权限、文件的属主、组的属主、文件大小、上次访问时间和上次修改时间。
3. **STATFS**。返回一个文件系统的状态：可用空间的大小、最佳传送大小等。例如 Unix的df命令使用此过程。
4. **LOOKUP**。查找一个文件。每当一个用户进程打开一个NFS服务器上的一个文件时，NFS客户调用此过程。
5. **READ**。从一个文件中读数据。客户说明文件的句柄、读操作的开始位置和读数据的最大字节数
6. **WRITE**。对一个文件进行写操作。客户说明文件的句柄、开始位置、写数据的字节数和要写的数据。
7. **CREATE**。创建一个文件。
8. **REMOVE**。删除一个文件。
9. **RENAME**。重命名一个文件。
10. **LINK**。为一个文件构造一个硬链接。硬链接是一个Unix的概念，指的是磁盘中的一个文件可以有任意多个目录项（即名字，也叫作硬链接）指向它。
11. **SYMLINK**。为一个文件创建一个符号链接。符号链接是一个包含另一个文件名字的文件。大多数引用符号链接的操作（例如，打开）实际上引用的是符号链接所指的文件。
12. **READLINK**。读一个符号链接。即返回符号链接所指的文件的名字。
13. **MKDIR**。创建一个目录。
14. **RMDIR**。删除一个目录。
15. **READDIR**。读一个目录。例如，Unix的ls命令使用此过程。

这些过程实际上有一个前缀 NFSPROC_，我们把它省略了。

### UDP还是TCP
NFS最初是用UDP写的，所有的厂商都提供了这种实现。最新的一些实现也支持TCP。

TCP支持主要用于广域网，它可以使文件操作更快。 NFS已经不再局限于局域网的使用。

当从LAN转换到WAN时，网络的动态特征变化得非常大。往返时间（round-trip time）变动范围大，拥塞经常发生。 WAN的这些特征使得我们考虑使用具有TCP属性的算法—慢启动，但是可以避免拥塞。既然UDP没有提供任何类似的东西，那么在NFS客户和服务器上加进同样的算法或者使用TCP。

### TCP上的NFS
让我们看一下使用TCP有什么不同。
1. 当服务器主机进行引导时，它启动一个NFS服务器，后者被动打开**TCP端口2049**，等待着客户的连接请求。这通常是另一个NFS服务器，正常的NFS UDP服务器在UDP端口2049等待着进入的U D P数据报。
2. 当客户使用TCP安装服务器上的文件系统时，它对服务器上的TCP端口2049做一个主动打开。这样就为这个文件系统在客户和服务器之间形成了一个**TCP连接**。如果同样的客户安装同样服务器上的另一个文件系统，就会创建另一个TCP连接。
3. 客户和服务器在它们连接的两端都要设置TCP的**keep alive**选项，这样双方都能检测到
对方主机崩溃，或者崩溃然后重启动。
4. 客户方所有使用这个服务器文件系统的应用程序**共享**这个TCP连接。对两个目录下所有文件的引用将共享同样的TCP连接。所以v3存在TCP PORT复用reused问题。
5. 如果客户检测到服务器已经崩溃，或者崩溃然后重启动（通过收到一个TCP差错**连接超时**或者对方**复位连接**，它尝试与服务器重新建立连接(使用相同的port发送SYN请求，服务端正处于`ESTABLISHED`状态)。客户做另一个主动打开为同一个文件系统请求重新建立TCP连接。在以前连接上超时的所有客户请求在新的连接上都会重新发出。
6. 如果客户机崩溃，那么当它崩溃时正在运行的应用程序也要崩溃。当客户机重新启动时，它很可能使用TCP**重新安装**服务器的文件系统，这将导致和服务器的另一个连接。客户和服务器之间针对同一个文件系统的前一个连接现在打开了一半(`half open`服务器方认为它还开着)，但是既然服务器设置了**keep alive**选项，当服务器发出下一个**keep alive**探查报文时，这个半开着的TCP连接就会被中止。

### 无状态
NFS的一个特征（NFS的批评者称之为NFS的一个瑕疵，而不是一个特征）是NFS服务器是无状态的。服务器并不记录哪个客户正在访问哪个文件。请注意一下在前面给出的NFS过程中，没有一个open操作和一个close操作。**LOOKUP**P过程的功能与**open**操作有些类似，但是服务器永远也不会知道客户对一个文件调用了**LOOKUP**过程之后是否会引用该文件。

无状态设计的理由是为了在服务器崩溃并且重启动时，简化服务器的崩溃恢复操作。

### 服务器崩溃(当使用UDP时，NFS客户代码完成超时和重传)
我们从一个崩溃然后重启动的NFS服务器上读一个文件。这个例子演示了无状态的服务器是如何使得客户不知道服务器的崩溃。除了在服务器崩溃然后重启动时一个时间上的暂停外，客户并不知道发生的问题，客户应用进程没有受到影响。

在传送过程中把以太网的网线拔掉，关闭然后重启动服务器主机，再重新将网线连上。客户被配置成每个NFS read过程读1024个字节。

在第130行和第131行我们看到两个请求超时，并且分别在 1 3 2行和1 3 3行重传。

第1个守护程序的间隔，四舍五入到两个十进制小数点，为0.68, 0.87, 1.74, 3.48, 6.96, 13.92, 20.0, 20.0, 20.0等等。第2个守护程序的间隔也是一样的（精确到两个小数点）。可以看出这些NFS客户使用了一个这样的超时定时器：间隔为 0.875秒的倍数，上限为20秒。每次超时后，重传间隔翻倍

客户重传发生在130 ~ 168行。在第169行我们看到服务器已经重启动，在它对第168行的客户NFS请求做出应答之前，它发送了一个ARP请求。对168行的响应被发送在171行。客户的READ操作继续进行下去。

除了从129行到171行5分钟的暂停，客户应用进程并不知道服务器崩溃然后又重启动了。这个服务器的崩溃对于客户是透明的。

客户要重传多久呢？客户有两个与此有关的选项。首先，如果服务器文件系统是**硬**安装的，客户就会永远重传下去。但是如果服务器文件系统是**软**安装的，客户重传了固定数目的次数之后就放弃。在**硬**安装的情况下，客户还有一个选项决定是否允许用户中断无限制的重传。如果客户主机安装服务器文件系统时说明了中断能力，并且如果我们不想在服务器崩溃之后等5分钟，等着服务器重启动，就可以键入一个中断键以终止客户应用

如果使用的是TCP，包含着服务器应答的TCP报文段在网络中丢失了，当服务器的TCP模块没有从客户的TC P模块收到一个确认时，它将超时，并重传应答。最终，这个报文段将到达客户的TCP。这里不同的是两个TCP模块完成超时和重传，而不是NFS客户和服务器（当使用UDP时，NFS客户代码完成超时和重传）。因此，NFS客户并不知道应答丢失了，需要被重传。

### NFSv3

我们总结一下第2版和第3版的主要区别。
1. V2中的**文件句柄**是32字节的固定大小的数组。在V3中，它变成了一个最多为**64**个字节的可变长度的数组。在 XDR中，一个可变长度的数组被编码为一个 4字节的数组成员个数跟着实际的数组成员字节。这样在实现时减少了文件句柄的长度，例如Unix只需要12个字节，但又允许非Unix实现维护另外的信息。
2. V2将每个READ和WRITE RPC过程可以读写的数据限制为8192个字节。这个限制在V3中取消了，这就意味着一个UDP上的实现只受到IP数据报大小的限制（**65535**字节）。这样允许在更快的网络上读写更大的分组。
3. 文件大小以及READ和WRITE过程开始偏移的字节从32字节扩充到64字节，允许读写更大的文件。
4. 每个影响文件属性值的调用都返回文件的属性。这样减少了客户调用 GETATTR过程的次数。
5. WRITE过程可以是**异步**的，而在V2中要求同步的WRITE过程。这样可以提高WRITE过程的性能。
6. V3中删去了一个过程（STATFS），增加了七个过程： ACCESS（检查文件访问权限）、MKNOD（创建一个Unix特殊文件）、READDIRPLUS（返回一个目录中的文件名字和它们的属性）、FSINFO（返回一个文件系统的静态信息）、FSSTAT（返回一个文件系统的动态信息）、PATH CONF（返回一个文件的 POSIX.1信息）和COMMIT（将以前的异步写操作提交到外存中）。

### NFSv4的主要新特性

**伪文件系统**:

NFSv4将所有共享使用一个虚拟文件系统展示给客户端。伪文件系统根目录(/)使用fsid=0标示，只有一个共享可以是fsid=0。客户端需要使用“nfs server ip:/”挂载伪文件系统，伪文件系统一般使用RO方式共享，其他共享可以通过mount –bind选项在伪文件系统目录下挂载。客户端挂载过程需要通过`mount –t nfs4`指定NFS版本为4，默认采用nfsv3。

**TCP作为传输层**：

NFSv3同时支持TCP和UDP传输层协议。UDP是一种不可靠协议，相比TCP而言可以获得更好性能，丢包和拥塞问题交由应用程序处理;相反TCP是一种可靠传输协议，拥有自己的拥塞控制和丢包重传机制。NFSv4协议明确要求传输层提供拥塞控制功能，因此NFSv4使用TCP作为传输层，另外NFSv4对TCP重传规则有严格限制。

**网络端口**：

NFSv3使用大量辅助协议，客户访问过程首先需要通过portmap/rpcbind获取rpc.mounted监听端口，然后nfs客户端访问rpc.mounted，nfs服务器根据/etc/exports文件进行客户身份验证，验证通过后nfs客户端才能与rpc.nfsd建立联系并访问共享。客户端与服务器数据交互过程的配额管理，文件锁管理以及nfs协议数据统计过程都由单独rpc进程来完成。所有这些进程除了portmap和nfsd之外都是监听动态随机端口。NFSv4自身集成辅助协议，**只需要TCP 2049一个端口即可**，这样极大方便NFS在防火墙后环境中部署。 v4版本已不再与rpcbind  lockd和rpc.statd daemons交互。 rpc.mountd daemon仍是必需，主要用于设置export，而不参与任何写操作

**服务器端拷贝**：

如果客户需要从一个NFS服务器拷贝数据到另外一个NFS服务器,nfsv4可以让两台NFS服务器之间直接拷贝数据，不需要经过客户端。

**资源预留和回收**：

NFSv4为虚拟分配提供的新特性。随着存储虚拟分配功能的普及使用，nfsv4可以为预留固定大小的存储空间;同样在文件系统上删除文件后，也能够在存储上面释放相应空间。

**国际化支持**：

NFSv4文件名、目录、链接、用户与组可以使用**UTF-8字符集**，UTF-8兼容ASCII码，使得NFSv4支持更多语言。

**RPC合并调用**：

NFSv4允许将多个请求合并为一个rpc引用，在NFSv3每个请求对应一个rpc调用。WAN环境中，NFSv4合并rpc调用可以显著降低延迟。

**安全性**：

NFSv4用户验证采用`用户名+域名`的模式，与Windows AD验证方式类似，NFSv4强制使用Kerberos验证方式。(Kerberos与Windows AD都遵循相同RFC1510标准)，这样方便windows和*nix环境混合部署。

**pNFS**

并行NFS文件系统，元数据服务器负责用户请求调度、数据服务器负责客户请求处理。pNFS需要NFS服务器和客户端协同支持。

### 问答

如果NFS服务器关机时，把它的以太网卡给换掉了，将会发生什么事情？

改变服务器的以太网卡就改变了它的物理地址。它仍然必须在能够应答NFS请求之前，向sun发送一
个请求sun的物理地址的ARP请求。因为sun已经有了svr4的一个ARP登记项，它从这个ARP请求中根据发送者的（新）硬件地址更新这个登记项。

每个主机最多只有102 个保留端口，所以保留端口是很缺乏的。如果一个N F S服务器要求它的客户拥有保留端口（公共的端口），一个NFS客户使用TCP安装了N个不同的服务器上的N个文件系统，那么客户对每个连接都需要一个不同的保留端口号吗？

不。NFS客户可以为不同的服务器主机使用相同的本地的保留端口号。 TCP要求由本地IP地址、本地端口、远端IP地址和远端端口组成的4元组是唯一的，对于每个服务器主机来说，远端的IP地址是不同的。

### NFS 服务器的配置

安装

```
yum -y install nfs
```

配置 NFS 共享目录`/etc/exports`

在该文件中，一行表示一个共享目录。请按以下格式进行修改：

`共享目录路径  允许的IP或主机 1(选项 1,选项 2,...)  允许的IP或主机名2(选项 1,选项 2,...)   ...`

例如允许任意主机以匿名身份读写 /tmp 目录；允许 10.0.0.1 以root的身份读写/root目录；允许10.0.0.2以root的身份读取/root目录。

```
/tmp *(rw,all_squash)
/root 10.0.0.1(rw,no_root_squash) 10.0.0.2(ro,no_root_squash)
```

启动 NFS 服务
```
systemctl start nfs
```
如需开机自启动，请执行：
```
systemctl enable nfs
```
更新 NFS 配置
如果修改了 NFS 配置文件，我们可以通过以下命令直接使新的配置文件生效而不用中断服务。
```
exportfs -rv
```
或
```
systemctl reload nfs
```

如果 NFS 服务器上开启了防火墙，那么就必须把 NFS 服务器使用的端口固定下来，而不能使用RPC 随机分配的端口。
```
echo "MOUNTD_PORT=52101" >> /etc/sysconfig/nfs 
echo "STATD_PORT=52102" >> /etc/sysconfig/nfs
echo "LOCKD_TCPPORT=52103" >> /etc/sysconfig/nfs
echo "LOCKD_UDPPORT=52104" >> /etc/sysconfig/nfs
```
然后重启 NFS 服务，防火墙配置打开 TCP/UDP 111 2049 52101 52102 52103 52104 端口。

### NFS 客户端的配置
安装
```
yum -y install nfs-utils
```
查看服务器的共享目录
```
showmount -e <服务器 IP 或主机名>
```

查看上面服务器共享出来的目录（IP 为 10.0.0.101）。
```
showmount -e 10.0.0.101
```
执行结果：
```
Export list for 10.0.0.101:
/tmp  *
/root 10.0.0.2,10.0.0.1
```
挂载 NFS 服务器上的共享目录
```
mount.nfs <服务器 IP 或主机名>:<共享路径> <挂载点> [-o <选项>]
```
-o选项：
选项|功能
---|:--:
bg|后台执行任务挂载
soft|服务器无响应时提示出错而不是一直尝试挂载
hard|NFS CLIENT会不断的尝试与SERVER的连接，直到MOUNT上
tcp|使用tcp模式
rsize=|读取块大小
wsize=|写入块大小
nfsvers=|设定要使用的NFS版本
minorversion=|小版本 `mount -o nfsvers=4,minorversion=1 NFSSERVER:/unix /unix`
mountport|设定mount的端口  
port|根据server端export出的端口设定
timeo=|设置超时时间，当数据传输遇到问题时，会根据这个参数尝试进行重新传输。默认值是0.7秒。如果网络连接不是很稳定的话就要加大这个数值，并且推荐使用HARD MOUNT方式，同时最好也加上INTR参数，这样你就可以终止任何挂起的文件访问。  
intr|允许通知中断一个NFS调用。当服务器没有应答需要放弃的时候有用处。 


例如
挂载上面服务器共享出来的 /tmp 目录到本机的 /mnt 上，并验证结果。
```
mount.nfs 10.0.0.101:/tmp /mnt/
mount | grep nfs
```
执行结果：
```
10.0.0.101:/tmp on /mnt type nfs4 (rw,relatime,vers=4.1,rsize=131072,wsize=131072,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=10.0.0.128,local_lock=none,addr=10.0.0.101)
```

Linux客户端读NFS共享文件时是多个READ Call连续发出去的。这个方式跟Windows XP读CIFS共享文件有所不同。Windows XP不会连续发READ Call，而是先发一个Call，等收到Reply后再发下一个。

除了读文件的方式，每个READ Call请求多少数据也会影响性能。这台Linux默认每次读131072字节，实验室里还有默认每次读32768字节的客户端。在高性能环境中，要手动指定一个比较大的值。我的Isilon实验室中，常常要调到512KB。这个值可以在mount时通过rsize参数来定义，比如 
```
mount -o rsize=524288 10.32.106.62:/code/tmp/code
```
查看NFS的运行状态，对于调整NFS的运行有很大帮助
```
nfsstat
```
  